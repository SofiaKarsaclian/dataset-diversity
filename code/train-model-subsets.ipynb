{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9806121,"sourceType":"datasetVersion","datasetId":6010727},{"sourceId":9822612,"sourceType":"datasetVersion","datasetId":6023103},{"sourceId":9825939,"sourceType":"datasetVersion","datasetId":6025668}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Train model based on the different samples\n\n\n\nUse same strategy as in the annomatic paper.\n\nTest on BABE\n","metadata":{}},{"cell_type":"code","source":"!pip install vendi_score\n\nimport logging\nimport warnings\nimport os\nimport pandas as pd\nimport numpy as np\nfrom vendi_score import vendi\nimport torch\nimport transformers\nfrom datasets import Dataset,load_dataset\nfrom torch.utils.data import DataLoader\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    AutoTokenizer,\n    DataCollatorWithPadding,\n    EarlyStoppingCallback,\n    Trainer,\n    TrainingArguments,\n)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    f1_score,\n    matthews_corrcoef,\n    precision_score,\n    recall_score,\n    roc_auc_score,\n)\n\ntransformers.logging.set_verbosity(transformers.logging.ERROR)\nlogging.disable(logging.ERROR)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T15:59:51.398322Z","iopub.execute_input":"2024-11-06T15:59:51.399025Z","iopub.status.idle":"2024-11-06T16:00:40.572522Z","shell.execute_reply.started":"2024-11-06T15:59:51.398972Z","shell.execute_reply":"2024-11-06T16:00:40.571588Z"}},"outputs":[{"name":"stdout","text":"Collecting vendi_score\n  Downloading vendi-score-0.0.3.tar.gz (13 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14 in /opt/conda/lib/python3.10/site-packages (from vendi_score) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from vendi_score) (1.14.1)\nRequirement already satisfied: scikit-learn>=1.1 in /opt/conda/lib/python3.10/site-packages (from vendi_score) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1->vendi_score) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.1->vendi_score) (3.5.0)\nBuilding wheels for collected packages: vendi_score\n  Building wheel for vendi_score (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for vendi_score: filename=vendi_score-0.0.3-py3-none-any.whl size=13316 sha256=a6f890a8646f8605b4cf9178167da288c0b711afcadefc051b29911041578222\n  Stored in directory: /root/.cache/pip/wheels/61/3e/72/6111f6ae4d7517f7d29a0bb1699bf6ea43ed48ff96bb10d723\nSuccessfully built vendi_score\nInstalling collected packages: vendi_score\nSuccessfully installed vendi_score-0.0.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Load subsamples\nsampled_dfs = {}\n\nsamples_folder = \"/kaggle/input/dirichlet-source-party/subsamples\"\n\nfor filename in os.listdir(samples_folder):\n    if filename.endswith(\".csv\"):\n        sample_name = filename.split(\".\")[0]\n        sampled_dfs[sample_name] = pd.read_csv(os.path.join(samples_folder, filename))\n\n\n\n# Display the keys of the sampled_dfs dictionary to verify the loaded subsamples\nprint(sampled_dfs.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T16:00:40.574246Z","iopub.execute_input":"2024-11-06T16:00:40.574489Z","iopub.status.idle":"2024-11-06T16:00:41.060889Z","shell.execute_reply.started":"2024-11-06T16:00:40.574457Z","shell.execute_reply":"2024-11-06T16:00:41.060046Z"}},"outputs":[{"name":"stdout","text":"dict_keys(['alpha_10_idx_2', 'alpha_10_idx_3', 'alpha_1_idx_1', 'alpha_100_idx_3', 'alpha_10_idx_1', 'alpha_1000_idx_1', 'alpha_0_01_idx_3', 'alpha_1_idx_2', 'alpha_100_idx_2', 'alpha_inf_idx_2', 'alpha_100_idx_1', 'alpha_inf_idx_3', 'alpha_1000_idx_2', 'alpha_0_1_idx_1', 'alpha_0_01_idx_2', 'alpha_0_01_idx_1', 'alpha_0_1_idx_3', 'alpha_inf_idx_1', 'alpha_1_idx_3', 'alpha_1000_idx_3', 'alpha_0_1_idx_2'])\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Define Vendi Score function for diversity measure\n\ndef vs_source(df):\n    features= df[['reliability', 'bias']].to_numpy()\n    distances= np.sqrt(np.sum((features[:, np.newaxis] - features[np.newaxis, :]) ** 2, axis=-1))\n    similarity_matrix = 1 / (1 + distances)\n\n    vs = vendi.score_K(similarity_matrix)\n    return vs\n\n\n\nfor name, df in sampled_dfs.items():\n    # VS score\n    print(vs_source(df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T16:00:41.062530Z","iopub.execute_input":"2024-11-06T16:00:41.063243Z","iopub.status.idle":"2024-11-06T16:01:16.521553Z","shell.execute_reply.started":"2024-11-06T16:00:41.063191Z","shell.execute_reply":"2024-11-06T16:01:16.520458Z"}},"outputs":[{"name":"stdout","text":"42.36204969411056\n41.89943211470747\n29.0637241180812\n42.23270525836314\n40.77482204321009\n42.46382987405022\n8.810501531372692\n26.742814429553615\n42.372671618394776\n43.77923979483535\n41.0264544016782\n42.311102025241894\n40.88155173576922\n8.751802312073396\n8.42884902837399\n12.809857865035188\n18.217655212962526\n42.12518033568915\n29.666980490335277\n41.61326489845395\n21.20190529122967\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"Fine-tune Roberta model on the different subsamples","metadata":{}},{"cell_type":"code","source":"# Definitions\n\nbase_model = \"roberta-base\"\ndevice = (\n    torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n)\n\n# Prepare Model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    base_model,\n    num_labels=2,\n)\ntokenizer = AutoTokenizer.from_pretrained(base_model)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer) # dynammically pads sequences to the length of the longest sequence in each batch\n\n\n# the pretrained head of roberta is discarded and replaced with a randomly initialized classification head","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T16:01:16.523494Z","iopub.execute_input":"2024-11-06T16:01:16.523746Z","iopub.status.idle":"2024-11-06T16:01:21.054404Z","shell.execute_reply.started":"2024-11-06T16:01:16.523713Z","shell.execute_reply":"2024-11-06T16:01:21.053454Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945b60379c68475094b7ec30e6a272f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3aa9d345c2a4be28f5b73ef2833a8ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f672d736aab140fab267bd09977fce80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64bf736e6bca490d971f73bf533fc6b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab37345b3fd04beb9e0e80043ce8b3ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"395205a998d94dcbb5e3d8017aaf5d98"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Define metrics\ndef compute_metrics_hf(preds):\n    \"\"\"computes F1 score and accuracy over dataset\n    Args:\n        model (any type): model for evaluation\n        testing_dataloader (huggingface dataset): self explained\n    Returns:\n        dict\n    \"\"\"\n    y_pred=preds.predictions\n    y_true=preds.label_ids\n    y_pred=y_pred.argmax(axis=1)\n    mcc=matthews_corrcoef(y_true,y_pred)\n    f1=f1_score(y_true,y_pred)\n    precision=precision_score(y_true,y_pred)\n    recall=recall_score(y_true,y_pred)\n    roc_auc=roc_auc_score(y_true,y_pred)\n    return{\n        \"mcc\":mcc,\n        \"f1\":f1,\n        \"precision\":precision,\n        \"recall\":recall,\n        \"roc_auc\":roc_auc,\n    }\n\ndef compute_metrics(testing_dataloader,model):\n    \"\"\"computes F1 score and accuracy over dataset\n    Args:\n        model (any type): model for evaluation\n        testing_dataloader (huggingface dataset): self explained\n    Returns:\n        dict\n    \"\"\"\n    y_true=[]\n    y_pred=[]\n    model.eval()\n    for batch in testing_dataloader:\n        batch={k:v.to(model.device)for k,v in batch.items()}\n        with torch.no_grad():\n            outputs=model(**batch)\n        logits=outputs.logits\n        predictions=torch.argmax(logits,dim=-1)\n        y_true.extend(batch[\"labels\"].tolist())\n        y_pred.extend(predictions.tolist())\n    mcc=matthews_corrcoef(y_true,y_pred)\n    f1=f1_score(y_true,y_pred)\n    precision=precision_score(y_true,y_pred)\n    recall=recall_score(y_true,y_pred)\n    roc_auc=roc_auc_score(y_true,y_pred)\n    return{\n        \"mcc\":mcc,\n        \"f1\":f1,\n        \"precision\":precision,\n        \"recall\":recall,\n        \"roc_auc\":roc_auc,\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T16:01:21.055663Z","iopub.execute_input":"2024-11-06T16:01:21.055892Z","iopub.status.idle":"2024-11-06T16:01:21.066246Z","shell.execute_reply.started":"2024-11-06T16:01:21.055860Z","shell.execute_reply":"2024-11-06T16:01:21.065372Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# metrics and vs scores\nresults_list=[]\n\ndef tokenize_function(examples):\n    return tokenizer(examples['text'], padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n\n# Import BABE for test sets\nbabe= load_dataset(\"mediabiasgroup/BABE\")[\"train\"].to_pandas()\n\ndev_df, test_df = train_test_split(babe,test_size=0.67,random_state=42,stratify=babe['label'])\ndev_df = Dataset.from_pandas(dev_df).map(tokenize_function, batched=True)\ntest_df = Dataset.from_pandas(test_df).map(tokenize_function, batched=True)\n\ndev_df.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\ntest_df.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n\n\n\n# loop through each sampled df and evaluate the model\nfor name,df in sampled_dfs.items():\n    # VS score\n    df_vs= vs_source(df)\n    \n    # Convert to hf datasets\n    train_df=Dataset.from_pandas(df).map(tokenize_function,batched=True)\n    train_df.set_format(type='torch',columns=['input_ids','attention_mask','label'])\n\n    \n    training_args=TrainingArguments(\n        output_dir=\"./checkpoints\",\n        per_device_eval_batch_size=32,\n        per_device_train_batch_size=32,\n        num_train_epochs=3,\n        save_total_limit=3,\n        evaluation_strategy=\"steps\",\n        logging_steps=50,\n        eval_steps=50,\n        save_steps=50,\n        disable_tqdm=False,\n        weight_decay=0.05,\n        learning_rate=2e-5,\n        # run_name=\"annomatic_test_eval\",\n        metric_for_best_model=\"eval_loss\",\n        save_strategy=\"steps\",\n        load_best_model_at_end=True,\n        remove_unused_columns=False,\n    )\n\n    # Trainer initialization\n    trainer=Trainer(\n        model,\n        training_args,\n        train_dataset=train_df,\n        eval_dataset=dev_df,\n        tokenizer=tokenizer,\n        compute_metrics=compute_metrics_hf,\n        data_collator=data_collator,\n        callbacks=[\n            EarlyStoppingCallback(\n                early_stopping_patience=5,\n                early_stopping_threshold=0.0,\n            ),\n        ],\n    )\n\n    # Train the model\n    trainer.train()\n    \n    # Evaluate on the test set\n    eval_dataloader=DataLoader(\n        test_df,\n        batch_size=32,\n        collate_fn=data_collator,\n    )\n    \n    metrics=compute_metrics(eval_dataloader,model)\n    metrics['vs']=df_vs  # Add the vs score to the metrics\n    metrics['subsample']=name  # Add the df name   \n    results_list.append(metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T16:03:20.521660Z","iopub.execute_input":"2024-11-06T16:03:20.522510Z","iopub.status.idle":"2024-11-06T16:52:22.504936Z","shell.execute_reply.started":"2024-11-06T16:03:20.522449Z","shell.execute_reply":"2024-11-06T16:52:22.504115Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1029 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98df832598fe4c998053ac21d43c6e89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2092 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cac9eec8ab9d4b6cbe34982ae2fb66b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43fe4a17ea6346338e2ec65242d3ce3b"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111293838888893, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2e405eb2dfd4df9908a413c498f67d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241106_160359-khi7a06m</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/sillm/huggingface/runs/khi7a06m' target=\"_blank\">./checkpoints</a></strong> to <a href='https://wandb.ai/sillm/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/sillm/huggingface' target=\"_blank\">https://wandb.ai/sillm/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/sillm/huggingface/runs/khi7a06m' target=\"_blank\">https://wandb.ai/sillm/huggingface/runs/khi7a06m</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 01:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.607800</td>\n      <td>0.413034</td>\n      <td>0.627590</td>\n      <td>0.835509</td>\n      <td>0.834783</td>\n      <td>0.836237</td>\n      <td>0.813723</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.417300</td>\n      <td>0.394982</td>\n      <td>0.645932</td>\n      <td>0.842382</td>\n      <td>0.846831</td>\n      <td>0.837979</td>\n      <td>0.823385</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d58e57405c0d4c578c37161445a3be86"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:04, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.440900</td>\n      <td>0.388591</td>\n      <td>0.620889</td>\n      <td>0.830255</td>\n      <td>0.838366</td>\n      <td>0.822300</td>\n      <td>0.811150</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.319500</td>\n      <td>0.429888</td>\n      <td>0.632372</td>\n      <td>0.820465</td>\n      <td>0.880240</td>\n      <td>0.768293</td>\n      <td>0.818212</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66e0aaea9cf2471faec50a6d19a8cb80"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.429500</td>\n      <td>0.402447</td>\n      <td>0.616734</td>\n      <td>0.833333</td>\n      <td>0.822034</td>\n      <td>0.844948</td>\n      <td>0.807089</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.301900</td>\n      <td>0.488229</td>\n      <td>0.604703</td>\n      <td>0.809963</td>\n      <td>0.860784</td>\n      <td>0.764808</td>\n      <td>0.804382</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68da8c7aab724b54aa275c925395a20c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.407600</td>\n      <td>0.402955</td>\n      <td>0.620334</td>\n      <td>0.836457</td>\n      <td>0.818333</td>\n      <td>0.855401</td>\n      <td>0.807920</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.284700</td>\n      <td>0.451307</td>\n      <td>0.633519</td>\n      <td>0.828959</td>\n      <td>0.862524</td>\n      <td>0.797909</td>\n      <td>0.818735</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2997 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a061c05383324f8c90ecf8ef39a6ac4d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.421800</td>\n      <td>0.417259</td>\n      <td>0.596184</td>\n      <td>0.835703</td>\n      <td>0.764451</td>\n      <td>0.921603</td>\n      <td>0.781681</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.275700</td>\n      <td>0.436230</td>\n      <td>0.643329</td>\n      <td>0.838938</td>\n      <td>0.852518</td>\n      <td>0.825784</td>\n      <td>0.822782</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8777ef85f44f45dc86413fcc8936bf79"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.410200</td>\n      <td>0.375317</td>\n      <td>0.642410</td>\n      <td>0.844635</td>\n      <td>0.832487</td>\n      <td>0.857143</td>\n      <td>0.819780</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.277600</td>\n      <td>0.418805</td>\n      <td>0.622968</td>\n      <td>0.830986</td>\n      <td>0.839858</td>\n      <td>0.822300</td>\n      <td>0.812249</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6adadc961b59439e9cda0cd920fade69"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.380000</td>\n      <td>0.401402</td>\n      <td>0.623586</td>\n      <td>0.844408</td>\n      <td>0.789394</td>\n      <td>0.907666</td>\n      <td>0.801085</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.241900</td>\n      <td>0.486680</td>\n      <td>0.616650</td>\n      <td>0.838602</td>\n      <td>0.802548</td>\n      <td>0.878049</td>\n      <td>0.802761</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2997 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c36dcce208d245c78af675cbfa7aaa99"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.382300</td>\n      <td>0.395819</td>\n      <td>0.638325</td>\n      <td>0.846605</td>\n      <td>0.815832</td>\n      <td>0.879791</td>\n      <td>0.814621</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.246000</td>\n      <td>0.455108</td>\n      <td>0.628189</td>\n      <td>0.841216</td>\n      <td>0.816393</td>\n      <td>0.867596</td>\n      <td>0.810721</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2997 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edb5fab4316a4bc3ab8c24ab00216a1a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.362400</td>\n      <td>0.377101</td>\n      <td>0.653761</td>\n      <td>0.835165</td>\n      <td>0.880309</td>\n      <td>0.794425</td>\n      <td>0.829081</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.237800</td>\n      <td>0.425663</td>\n      <td>0.654157</td>\n      <td>0.839640</td>\n      <td>0.869403</td>\n      <td>0.811847</td>\n      <td>0.829000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"187c39f0fe944ba4b54a78eb4b5ce308"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.328800</td>\n      <td>0.356982</td>\n      <td>0.666304</td>\n      <td>0.854436</td>\n      <td>0.844974</td>\n      <td>0.864111</td>\n      <td>0.832056</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.201400</td>\n      <td>0.480007</td>\n      <td>0.654765</td>\n      <td>0.848485</td>\n      <td>0.843373</td>\n      <td>0.853659</td>\n      <td>0.826829</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2997 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83d4fb9470b84f31b30526c3e116253d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 01:58, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.349600</td>\n      <td>0.394987</td>\n      <td>0.661672</td>\n      <td>0.849387</td>\n      <td>0.853873</td>\n      <td>0.844948</td>\n      <td>0.831265</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.206800</td>\n      <td>0.492422</td>\n      <td>0.665047</td>\n      <td>0.848539</td>\n      <td>0.863063</td>\n      <td>0.834495</td>\n      <td>0.833731</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37cc7d14506b4e71b5d901ab0bcdd9e8"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.331700</td>\n      <td>0.357621</td>\n      <td>0.676317</td>\n      <td>0.858377</td>\n      <td>0.851027</td>\n      <td>0.865854</td>\n      <td>0.837322</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.194500</td>\n      <td>0.516598</td>\n      <td>0.665993</td>\n      <td>0.850615</td>\n      <td>0.858156</td>\n      <td>0.843206</td>\n      <td>0.833691</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ab645371284eb7bc4ac87a84bd896e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:05, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.335900</td>\n      <td>0.433694</td>\n      <td>0.642578</td>\n      <td>0.818613</td>\n      <td>0.899791</td>\n      <td>0.750871</td>\n      <td>0.822688</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.207100</td>\n      <td>0.485820</td>\n      <td>0.641350</td>\n      <td>0.832579</td>\n      <td>0.866290</td>\n      <td>0.801394</td>\n      <td>0.822675</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0437de5aab14aa49fe3fa18a43078ed"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:05, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.372700</td>\n      <td>0.380144</td>\n      <td>0.642410</td>\n      <td>0.844635</td>\n      <td>0.832487</td>\n      <td>0.857143</td>\n      <td>0.819780</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.242700</td>\n      <td>0.433923</td>\n      <td>0.648406</td>\n      <td>0.842568</td>\n      <td>0.850799</td>\n      <td>0.834495</td>\n      <td>0.824940</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e8ecf3d5e7c4f0081bbb10c851eaa7a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.255700</td>\n      <td>0.453339</td>\n      <td>0.650704</td>\n      <td>0.843034</td>\n      <td>0.853571</td>\n      <td>0.832753</td>\n      <td>0.826266</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.131500</td>\n      <td>0.611868</td>\n      <td>0.624303</td>\n      <td>0.838160</td>\n      <td>0.820000</td>\n      <td>0.857143</td>\n      <td>0.809890</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41ffad5121554ced85d5998763cd74c1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.355900</td>\n      <td>0.428586</td>\n      <td>0.620386</td>\n      <td>0.836177</td>\n      <td>0.819398</td>\n      <td>0.853659</td>\n      <td>0.808148</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.212800</td>\n      <td>0.524419</td>\n      <td>0.624234</td>\n      <td>0.838710</td>\n      <td>0.817881</td>\n      <td>0.860627</td>\n      <td>0.809434</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35a8b77283a94f088f19de9d4e82987e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.257200</td>\n      <td>0.436021</td>\n      <td>0.642222</td>\n      <td>0.845431</td>\n      <td>0.829146</td>\n      <td>0.862369</td>\n      <td>0.819097</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.136200</td>\n      <td>0.545084</td>\n      <td>0.618809</td>\n      <td>0.839834</td>\n      <td>0.801902</td>\n      <td>0.881533</td>\n      <td>0.803404</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3c721eae962445ea1aa749f33cb61d4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.291500</td>\n      <td>0.455623</td>\n      <td>0.613075</td>\n      <td>0.838017</td>\n      <td>0.797170</td>\n      <td>0.883275</td>\n      <td>0.799879</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.164000</td>\n      <td>0.521096</td>\n      <td>0.620600</td>\n      <td>0.835334</td>\n      <td>0.822635</td>\n      <td>0.848432</td>\n      <td>0.808831</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2998 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4365986231b44196aa7be67790cc4832"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 01:58, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.300600</td>\n      <td>0.413132</td>\n      <td>0.634927</td>\n      <td>0.830325</td>\n      <td>0.861423</td>\n      <td>0.801394</td>\n      <td>0.819378</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.161800</td>\n      <td>0.542608</td>\n      <td>0.624238</td>\n      <td>0.840067</td>\n      <td>0.812704</td>\n      <td>0.869338</td>\n      <td>0.808295</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2997 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c86123e5221446db611d03b5d805a46"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.288200</td>\n      <td>0.492392</td>\n      <td>0.644903</td>\n      <td>0.815385</td>\n      <td>0.909871</td>\n      <td>0.738676</td>\n      <td>0.823184</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.143800</td>\n      <td>0.525092</td>\n      <td>0.642846</td>\n      <td>0.839506</td>\n      <td>0.850000</td>\n      <td>0.829268</td>\n      <td>0.822326</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2999 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1c783d2ce584880847c3d7c490e615f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [141/141 02:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcc</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.320600</td>\n      <td>0.402045</td>\n      <td>0.644182</td>\n      <td>0.846416</td>\n      <td>0.829431</td>\n      <td>0.864111</td>\n      <td>0.819968</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.168500</td>\n      <td>0.545562</td>\n      <td>0.610266</td>\n      <td>0.833755</td>\n      <td>0.808511</td>\n      <td>0.860627</td>\n      <td>0.801742</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"results_df = pd.DataFrame(results_list)\nresults_df = results_df[['subsample'] + [col for col in results_df.columns if col != 'subsample']]\n\nresults['alpha'] = results['subsample'].str.extract(r'alpha_([\\d_]+)').replace('_', '.', regex=True)\nresults_df.to_csv(\"results_df.csv\", index=False)\n\n\n# df['alpha'] = df['name'].str.extract(r'alpha_([\\d_]+)').replace('_', '.', regex=True)\n\n\n# styled_df = test.style \\\n#     .highlight_max(color='lightgreen', axis=0, subset=results_df.columns.difference(['subsample'])) \\\n#     .highlight_min(color='lightcoral', axis=0, subset=results_df.columns.difference(['subsample']))\n\n\n\n# # Display the styled DataFrame\n\n# # styled_df.sort_values(by=[\"vs\"])\n# styled_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T16:01:24.595794Z","iopub.status.idle":"2024-11-06T16:01:24.596129Z","shell.execute_reply.started":"2024-11-06T16:01:24.595944Z","shell.execute_reply":"2024-11-06T16:01:24.595969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df = pd.DataFrame(results_list)\nresults_df = results_df[['subsample'] + [col for col in results_df.columns if col != 'subsample']]\n\nresults_df['alpha'] = results_df['subsample'].str.extract(r'alpha_(.*?)_idx').replace('_', '.', regex=True)\nresults_df['alpha'] = results_df['alpha'].replace(np.inf, float('inf'))\n\nresults_df = results_df.sort_values(by='alpha', ascending=True)\n\nresults_df.to_csv(\"results_df.csv\", index=False)\n\nresults_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T17:00:22.487153Z","iopub.execute_input":"2024-11-06T17:00:22.487502Z","iopub.status.idle":"2024-11-06T17:00:22.518321Z","shell.execute_reply.started":"2024-11-06T17:00:22.487456Z","shell.execute_reply":"2024-11-06T17:00:22.517473Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"           subsample       mcc        f1  precision    recall   roc_auc  \\\n15  alpha_0_01_idx_1  0.664689  0.855225   0.837305  0.873928  0.830053   \n14  alpha_0_01_idx_2  0.669845  0.851691   0.861404  0.842196  0.835785   \n6   alpha_0_01_idx_3  0.623381  0.843750   0.791729  0.903087  0.801976   \n20   alpha_0_1_idx_2  0.657920  0.851852   0.836364  0.867925  0.827051   \n16   alpha_0_1_idx_3  0.662145  0.852292   0.843697  0.861063  0.830100   \n13   alpha_0_1_idx_1  0.654072  0.849916   0.835821  0.864494  0.825336   \n18     alpha_1_idx_3  0.670253  0.843666   0.885849  0.805317  0.837324   \n2      alpha_1_idx_1  0.632944  0.839695   0.830537  0.849057  0.815457   \n7      alpha_1_idx_2  0.641333  0.847331   0.818545  0.878216  0.816538   \n0     alpha_10_idx_2  0.629546  0.836892   0.833333  0.840480  0.814409   \n4     alpha_10_idx_1  0.595312  0.834639   0.768398  0.913379  0.783363   \n1     alpha_10_idx_3  0.629848  0.834414   0.841325  0.827616  0.815536   \n8    alpha_100_idx_2  0.691974  0.856508   0.888479  0.826758  0.848044   \n3    alpha_100_idx_3  0.640293  0.844799   0.826765  0.863636  0.817887   \n10   alpha_100_idx_1  0.665343  0.852878   0.848176  0.857633  0.832164   \n19  alpha_1000_idx_3  0.661398  0.828358   0.907975  0.761578  0.832193   \n12  alpha_1000_idx_2  0.665285  0.837209   0.893866  0.787307  0.834798   \n5   alpha_1000_idx_1  0.640264  0.845059   0.825696  0.865352  0.817665   \n11   alpha_inf_idx_3  0.669800  0.856054   0.845318  0.867067  0.833641   \n17   alpha_inf_idx_1  0.624979  0.841674   0.806604  0.879931  0.807136   \n9    alpha_inf_idx_2  0.671625  0.857384   0.843854  0.871355  0.834166   \n\n           vs alpha  \n15  12.809858  0.01  \n14   8.428849  0.01  \n6    8.810502  0.01  \n20  21.201905   0.1  \n16  18.217655   0.1  \n13   8.751802   0.1  \n18  29.666980     1  \n2   29.063724     1  \n7   26.742814     1  \n0   42.362050    10  \n4   40.774822    10  \n1   41.899432    10  \n8   42.372672   100  \n3   42.232705   100  \n10  41.026454   100  \n19  41.613265  1000  \n12  40.881552  1000  \n5   42.463830  1000  \n11  42.311102   inf  \n17  42.125180   inf  \n9   43.779240   inf  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subsample</th>\n      <th>mcc</th>\n      <th>f1</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>roc_auc</th>\n      <th>vs</th>\n      <th>alpha</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>alpha_0_01_idx_1</td>\n      <td>0.664689</td>\n      <td>0.855225</td>\n      <td>0.837305</td>\n      <td>0.873928</td>\n      <td>0.830053</td>\n      <td>12.809858</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>alpha_0_01_idx_2</td>\n      <td>0.669845</td>\n      <td>0.851691</td>\n      <td>0.861404</td>\n      <td>0.842196</td>\n      <td>0.835785</td>\n      <td>8.428849</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>alpha_0_01_idx_3</td>\n      <td>0.623381</td>\n      <td>0.843750</td>\n      <td>0.791729</td>\n      <td>0.903087</td>\n      <td>0.801976</td>\n      <td>8.810502</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>alpha_0_1_idx_2</td>\n      <td>0.657920</td>\n      <td>0.851852</td>\n      <td>0.836364</td>\n      <td>0.867925</td>\n      <td>0.827051</td>\n      <td>21.201905</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>alpha_0_1_idx_3</td>\n      <td>0.662145</td>\n      <td>0.852292</td>\n      <td>0.843697</td>\n      <td>0.861063</td>\n      <td>0.830100</td>\n      <td>18.217655</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>alpha_0_1_idx_1</td>\n      <td>0.654072</td>\n      <td>0.849916</td>\n      <td>0.835821</td>\n      <td>0.864494</td>\n      <td>0.825336</td>\n      <td>8.751802</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>alpha_1_idx_3</td>\n      <td>0.670253</td>\n      <td>0.843666</td>\n      <td>0.885849</td>\n      <td>0.805317</td>\n      <td>0.837324</td>\n      <td>29.666980</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>alpha_1_idx_1</td>\n      <td>0.632944</td>\n      <td>0.839695</td>\n      <td>0.830537</td>\n      <td>0.849057</td>\n      <td>0.815457</td>\n      <td>29.063724</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>alpha_1_idx_2</td>\n      <td>0.641333</td>\n      <td>0.847331</td>\n      <td>0.818545</td>\n      <td>0.878216</td>\n      <td>0.816538</td>\n      <td>26.742814</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>alpha_10_idx_2</td>\n      <td>0.629546</td>\n      <td>0.836892</td>\n      <td>0.833333</td>\n      <td>0.840480</td>\n      <td>0.814409</td>\n      <td>42.362050</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>alpha_10_idx_1</td>\n      <td>0.595312</td>\n      <td>0.834639</td>\n      <td>0.768398</td>\n      <td>0.913379</td>\n      <td>0.783363</td>\n      <td>40.774822</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>alpha_10_idx_3</td>\n      <td>0.629848</td>\n      <td>0.834414</td>\n      <td>0.841325</td>\n      <td>0.827616</td>\n      <td>0.815536</td>\n      <td>41.899432</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>alpha_100_idx_2</td>\n      <td>0.691974</td>\n      <td>0.856508</td>\n      <td>0.888479</td>\n      <td>0.826758</td>\n      <td>0.848044</td>\n      <td>42.372672</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>alpha_100_idx_3</td>\n      <td>0.640293</td>\n      <td>0.844799</td>\n      <td>0.826765</td>\n      <td>0.863636</td>\n      <td>0.817887</td>\n      <td>42.232705</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>alpha_100_idx_1</td>\n      <td>0.665343</td>\n      <td>0.852878</td>\n      <td>0.848176</td>\n      <td>0.857633</td>\n      <td>0.832164</td>\n      <td>41.026454</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>alpha_1000_idx_3</td>\n      <td>0.661398</td>\n      <td>0.828358</td>\n      <td>0.907975</td>\n      <td>0.761578</td>\n      <td>0.832193</td>\n      <td>41.613265</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>alpha_1000_idx_2</td>\n      <td>0.665285</td>\n      <td>0.837209</td>\n      <td>0.893866</td>\n      <td>0.787307</td>\n      <td>0.834798</td>\n      <td>40.881552</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>alpha_1000_idx_1</td>\n      <td>0.640264</td>\n      <td>0.845059</td>\n      <td>0.825696</td>\n      <td>0.865352</td>\n      <td>0.817665</td>\n      <td>42.463830</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>alpha_inf_idx_3</td>\n      <td>0.669800</td>\n      <td>0.856054</td>\n      <td>0.845318</td>\n      <td>0.867067</td>\n      <td>0.833641</td>\n      <td>42.311102</td>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>alpha_inf_idx_1</td>\n      <td>0.624979</td>\n      <td>0.841674</td>\n      <td>0.806604</td>\n      <td>0.879931</td>\n      <td>0.807136</td>\n      <td>42.125180</td>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>alpha_inf_idx_2</td>\n      <td>0.671625</td>\n      <td>0.857384</td>\n      <td>0.843854</td>\n      <td>0.871355</td>\n      <td>0.834166</td>\n      <td>43.779240</td>\n      <td>inf</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# load results \n# results_df = pd.read_csv(\"/kaggle/input/results-df/results_df.csv\").sort_values(by=[\"vs\"], ascending=False)\n\nstyled_df = results_df.style \\\n    .highlight_max(color='lightgreen', axis=0, subset=results_df.columns.difference(['subsample', 'alpha'])) \\\n    .highlight_min(color='lightcoral', axis=0, subset=results_df.columns.difference(['subsample', 'alpha']))\n\nstyled_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T17:01:41.915308Z","iopub.execute_input":"2024-11-06T17:01:41.916355Z","iopub.status.idle":"2024-11-06T17:01:41.943909Z","shell.execute_reply.started":"2024-11-06T17:01:41.916299Z","shell.execute_reply":"2024-11-06T17:01:41.942932Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7ef8863844c0>","text/html":"<style type=\"text/css\">\n#T_128b4_row1_col6, #T_128b4_row10_col1, #T_128b4_row10_col3, #T_128b4_row10_col5, #T_128b4_row15_col2, #T_128b4_row15_col4 {\n  background-color: lightcoral;\n}\n#T_128b4_row10_col4, #T_128b4_row12_col1, #T_128b4_row12_col5, #T_128b4_row15_col3, #T_128b4_row20_col2, #T_128b4_row20_col6 {\n  background-color: lightgreen;\n}\n</style>\n<table id=\"T_128b4\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_128b4_level0_col0\" class=\"col_heading level0 col0\" >subsample</th>\n      <th id=\"T_128b4_level0_col1\" class=\"col_heading level0 col1\" >mcc</th>\n      <th id=\"T_128b4_level0_col2\" class=\"col_heading level0 col2\" >f1</th>\n      <th id=\"T_128b4_level0_col3\" class=\"col_heading level0 col3\" >precision</th>\n      <th id=\"T_128b4_level0_col4\" class=\"col_heading level0 col4\" >recall</th>\n      <th id=\"T_128b4_level0_col5\" class=\"col_heading level0 col5\" >roc_auc</th>\n      <th id=\"T_128b4_level0_col6\" class=\"col_heading level0 col6\" >vs</th>\n      <th id=\"T_128b4_level0_col7\" class=\"col_heading level0 col7\" >alpha</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_128b4_level0_row0\" class=\"row_heading level0 row0\" >15</th>\n      <td id=\"T_128b4_row0_col0\" class=\"data row0 col0\" >alpha_0_01_idx_1</td>\n      <td id=\"T_128b4_row0_col1\" class=\"data row0 col1\" >0.664689</td>\n      <td id=\"T_128b4_row0_col2\" class=\"data row0 col2\" >0.855225</td>\n      <td id=\"T_128b4_row0_col3\" class=\"data row0 col3\" >0.837305</td>\n      <td id=\"T_128b4_row0_col4\" class=\"data row0 col4\" >0.873928</td>\n      <td id=\"T_128b4_row0_col5\" class=\"data row0 col5\" >0.830053</td>\n      <td id=\"T_128b4_row0_col6\" class=\"data row0 col6\" >12.809858</td>\n      <td id=\"T_128b4_row0_col7\" class=\"data row0 col7\" >0.01</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row1\" class=\"row_heading level0 row1\" >14</th>\n      <td id=\"T_128b4_row1_col0\" class=\"data row1 col0\" >alpha_0_01_idx_2</td>\n      <td id=\"T_128b4_row1_col1\" class=\"data row1 col1\" >0.669845</td>\n      <td id=\"T_128b4_row1_col2\" class=\"data row1 col2\" >0.851691</td>\n      <td id=\"T_128b4_row1_col3\" class=\"data row1 col3\" >0.861404</td>\n      <td id=\"T_128b4_row1_col4\" class=\"data row1 col4\" >0.842196</td>\n      <td id=\"T_128b4_row1_col5\" class=\"data row1 col5\" >0.835785</td>\n      <td id=\"T_128b4_row1_col6\" class=\"data row1 col6\" >8.428849</td>\n      <td id=\"T_128b4_row1_col7\" class=\"data row1 col7\" >0.01</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row2\" class=\"row_heading level0 row2\" >6</th>\n      <td id=\"T_128b4_row2_col0\" class=\"data row2 col0\" >alpha_0_01_idx_3</td>\n      <td id=\"T_128b4_row2_col1\" class=\"data row2 col1\" >0.623381</td>\n      <td id=\"T_128b4_row2_col2\" class=\"data row2 col2\" >0.843750</td>\n      <td id=\"T_128b4_row2_col3\" class=\"data row2 col3\" >0.791729</td>\n      <td id=\"T_128b4_row2_col4\" class=\"data row2 col4\" >0.903087</td>\n      <td id=\"T_128b4_row2_col5\" class=\"data row2 col5\" >0.801976</td>\n      <td id=\"T_128b4_row2_col6\" class=\"data row2 col6\" >8.810502</td>\n      <td id=\"T_128b4_row2_col7\" class=\"data row2 col7\" >0.01</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row3\" class=\"row_heading level0 row3\" >20</th>\n      <td id=\"T_128b4_row3_col0\" class=\"data row3 col0\" >alpha_0_1_idx_2</td>\n      <td id=\"T_128b4_row3_col1\" class=\"data row3 col1\" >0.657920</td>\n      <td id=\"T_128b4_row3_col2\" class=\"data row3 col2\" >0.851852</td>\n      <td id=\"T_128b4_row3_col3\" class=\"data row3 col3\" >0.836364</td>\n      <td id=\"T_128b4_row3_col4\" class=\"data row3 col4\" >0.867925</td>\n      <td id=\"T_128b4_row3_col5\" class=\"data row3 col5\" >0.827051</td>\n      <td id=\"T_128b4_row3_col6\" class=\"data row3 col6\" >21.201905</td>\n      <td id=\"T_128b4_row3_col7\" class=\"data row3 col7\" >0.1</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row4\" class=\"row_heading level0 row4\" >16</th>\n      <td id=\"T_128b4_row4_col0\" class=\"data row4 col0\" >alpha_0_1_idx_3</td>\n      <td id=\"T_128b4_row4_col1\" class=\"data row4 col1\" >0.662145</td>\n      <td id=\"T_128b4_row4_col2\" class=\"data row4 col2\" >0.852292</td>\n      <td id=\"T_128b4_row4_col3\" class=\"data row4 col3\" >0.843697</td>\n      <td id=\"T_128b4_row4_col4\" class=\"data row4 col4\" >0.861063</td>\n      <td id=\"T_128b4_row4_col5\" class=\"data row4 col5\" >0.830100</td>\n      <td id=\"T_128b4_row4_col6\" class=\"data row4 col6\" >18.217655</td>\n      <td id=\"T_128b4_row4_col7\" class=\"data row4 col7\" >0.1</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row5\" class=\"row_heading level0 row5\" >13</th>\n      <td id=\"T_128b4_row5_col0\" class=\"data row5 col0\" >alpha_0_1_idx_1</td>\n      <td id=\"T_128b4_row5_col1\" class=\"data row5 col1\" >0.654072</td>\n      <td id=\"T_128b4_row5_col2\" class=\"data row5 col2\" >0.849916</td>\n      <td id=\"T_128b4_row5_col3\" class=\"data row5 col3\" >0.835821</td>\n      <td id=\"T_128b4_row5_col4\" class=\"data row5 col4\" >0.864494</td>\n      <td id=\"T_128b4_row5_col5\" class=\"data row5 col5\" >0.825336</td>\n      <td id=\"T_128b4_row5_col6\" class=\"data row5 col6\" >8.751802</td>\n      <td id=\"T_128b4_row5_col7\" class=\"data row5 col7\" >0.1</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row6\" class=\"row_heading level0 row6\" >18</th>\n      <td id=\"T_128b4_row6_col0\" class=\"data row6 col0\" >alpha_1_idx_3</td>\n      <td id=\"T_128b4_row6_col1\" class=\"data row6 col1\" >0.670253</td>\n      <td id=\"T_128b4_row6_col2\" class=\"data row6 col2\" >0.843666</td>\n      <td id=\"T_128b4_row6_col3\" class=\"data row6 col3\" >0.885849</td>\n      <td id=\"T_128b4_row6_col4\" class=\"data row6 col4\" >0.805317</td>\n      <td id=\"T_128b4_row6_col5\" class=\"data row6 col5\" >0.837324</td>\n      <td id=\"T_128b4_row6_col6\" class=\"data row6 col6\" >29.666980</td>\n      <td id=\"T_128b4_row6_col7\" class=\"data row6 col7\" >1</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row7\" class=\"row_heading level0 row7\" >2</th>\n      <td id=\"T_128b4_row7_col0\" class=\"data row7 col0\" >alpha_1_idx_1</td>\n      <td id=\"T_128b4_row7_col1\" class=\"data row7 col1\" >0.632944</td>\n      <td id=\"T_128b4_row7_col2\" class=\"data row7 col2\" >0.839695</td>\n      <td id=\"T_128b4_row7_col3\" class=\"data row7 col3\" >0.830537</td>\n      <td id=\"T_128b4_row7_col4\" class=\"data row7 col4\" >0.849057</td>\n      <td id=\"T_128b4_row7_col5\" class=\"data row7 col5\" >0.815457</td>\n      <td id=\"T_128b4_row7_col6\" class=\"data row7 col6\" >29.063724</td>\n      <td id=\"T_128b4_row7_col7\" class=\"data row7 col7\" >1</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row8\" class=\"row_heading level0 row8\" >7</th>\n      <td id=\"T_128b4_row8_col0\" class=\"data row8 col0\" >alpha_1_idx_2</td>\n      <td id=\"T_128b4_row8_col1\" class=\"data row8 col1\" >0.641333</td>\n      <td id=\"T_128b4_row8_col2\" class=\"data row8 col2\" >0.847331</td>\n      <td id=\"T_128b4_row8_col3\" class=\"data row8 col3\" >0.818545</td>\n      <td id=\"T_128b4_row8_col4\" class=\"data row8 col4\" >0.878216</td>\n      <td id=\"T_128b4_row8_col5\" class=\"data row8 col5\" >0.816538</td>\n      <td id=\"T_128b4_row8_col6\" class=\"data row8 col6\" >26.742814</td>\n      <td id=\"T_128b4_row8_col7\" class=\"data row8 col7\" >1</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row9\" class=\"row_heading level0 row9\" >0</th>\n      <td id=\"T_128b4_row9_col0\" class=\"data row9 col0\" >alpha_10_idx_2</td>\n      <td id=\"T_128b4_row9_col1\" class=\"data row9 col1\" >0.629546</td>\n      <td id=\"T_128b4_row9_col2\" class=\"data row9 col2\" >0.836892</td>\n      <td id=\"T_128b4_row9_col3\" class=\"data row9 col3\" >0.833333</td>\n      <td id=\"T_128b4_row9_col4\" class=\"data row9 col4\" >0.840480</td>\n      <td id=\"T_128b4_row9_col5\" class=\"data row9 col5\" >0.814409</td>\n      <td id=\"T_128b4_row9_col6\" class=\"data row9 col6\" >42.362050</td>\n      <td id=\"T_128b4_row9_col7\" class=\"data row9 col7\" >10</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row10\" class=\"row_heading level0 row10\" >4</th>\n      <td id=\"T_128b4_row10_col0\" class=\"data row10 col0\" >alpha_10_idx_1</td>\n      <td id=\"T_128b4_row10_col1\" class=\"data row10 col1\" >0.595312</td>\n      <td id=\"T_128b4_row10_col2\" class=\"data row10 col2\" >0.834639</td>\n      <td id=\"T_128b4_row10_col3\" class=\"data row10 col3\" >0.768398</td>\n      <td id=\"T_128b4_row10_col4\" class=\"data row10 col4\" >0.913379</td>\n      <td id=\"T_128b4_row10_col5\" class=\"data row10 col5\" >0.783363</td>\n      <td id=\"T_128b4_row10_col6\" class=\"data row10 col6\" >40.774822</td>\n      <td id=\"T_128b4_row10_col7\" class=\"data row10 col7\" >10</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row11\" class=\"row_heading level0 row11\" >1</th>\n      <td id=\"T_128b4_row11_col0\" class=\"data row11 col0\" >alpha_10_idx_3</td>\n      <td id=\"T_128b4_row11_col1\" class=\"data row11 col1\" >0.629848</td>\n      <td id=\"T_128b4_row11_col2\" class=\"data row11 col2\" >0.834414</td>\n      <td id=\"T_128b4_row11_col3\" class=\"data row11 col3\" >0.841325</td>\n      <td id=\"T_128b4_row11_col4\" class=\"data row11 col4\" >0.827616</td>\n      <td id=\"T_128b4_row11_col5\" class=\"data row11 col5\" >0.815536</td>\n      <td id=\"T_128b4_row11_col6\" class=\"data row11 col6\" >41.899432</td>\n      <td id=\"T_128b4_row11_col7\" class=\"data row11 col7\" >10</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row12\" class=\"row_heading level0 row12\" >8</th>\n      <td id=\"T_128b4_row12_col0\" class=\"data row12 col0\" >alpha_100_idx_2</td>\n      <td id=\"T_128b4_row12_col1\" class=\"data row12 col1\" >0.691974</td>\n      <td id=\"T_128b4_row12_col2\" class=\"data row12 col2\" >0.856508</td>\n      <td id=\"T_128b4_row12_col3\" class=\"data row12 col3\" >0.888479</td>\n      <td id=\"T_128b4_row12_col4\" class=\"data row12 col4\" >0.826758</td>\n      <td id=\"T_128b4_row12_col5\" class=\"data row12 col5\" >0.848044</td>\n      <td id=\"T_128b4_row12_col6\" class=\"data row12 col6\" >42.372672</td>\n      <td id=\"T_128b4_row12_col7\" class=\"data row12 col7\" >100</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row13\" class=\"row_heading level0 row13\" >3</th>\n      <td id=\"T_128b4_row13_col0\" class=\"data row13 col0\" >alpha_100_idx_3</td>\n      <td id=\"T_128b4_row13_col1\" class=\"data row13 col1\" >0.640293</td>\n      <td id=\"T_128b4_row13_col2\" class=\"data row13 col2\" >0.844799</td>\n      <td id=\"T_128b4_row13_col3\" class=\"data row13 col3\" >0.826765</td>\n      <td id=\"T_128b4_row13_col4\" class=\"data row13 col4\" >0.863636</td>\n      <td id=\"T_128b4_row13_col5\" class=\"data row13 col5\" >0.817887</td>\n      <td id=\"T_128b4_row13_col6\" class=\"data row13 col6\" >42.232705</td>\n      <td id=\"T_128b4_row13_col7\" class=\"data row13 col7\" >100</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row14\" class=\"row_heading level0 row14\" >10</th>\n      <td id=\"T_128b4_row14_col0\" class=\"data row14 col0\" >alpha_100_idx_1</td>\n      <td id=\"T_128b4_row14_col1\" class=\"data row14 col1\" >0.665343</td>\n      <td id=\"T_128b4_row14_col2\" class=\"data row14 col2\" >0.852878</td>\n      <td id=\"T_128b4_row14_col3\" class=\"data row14 col3\" >0.848176</td>\n      <td id=\"T_128b4_row14_col4\" class=\"data row14 col4\" >0.857633</td>\n      <td id=\"T_128b4_row14_col5\" class=\"data row14 col5\" >0.832164</td>\n      <td id=\"T_128b4_row14_col6\" class=\"data row14 col6\" >41.026454</td>\n      <td id=\"T_128b4_row14_col7\" class=\"data row14 col7\" >100</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row15\" class=\"row_heading level0 row15\" >19</th>\n      <td id=\"T_128b4_row15_col0\" class=\"data row15 col0\" >alpha_1000_idx_3</td>\n      <td id=\"T_128b4_row15_col1\" class=\"data row15 col1\" >0.661398</td>\n      <td id=\"T_128b4_row15_col2\" class=\"data row15 col2\" >0.828358</td>\n      <td id=\"T_128b4_row15_col3\" class=\"data row15 col3\" >0.907975</td>\n      <td id=\"T_128b4_row15_col4\" class=\"data row15 col4\" >0.761578</td>\n      <td id=\"T_128b4_row15_col5\" class=\"data row15 col5\" >0.832193</td>\n      <td id=\"T_128b4_row15_col6\" class=\"data row15 col6\" >41.613265</td>\n      <td id=\"T_128b4_row15_col7\" class=\"data row15 col7\" >1000</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row16\" class=\"row_heading level0 row16\" >12</th>\n      <td id=\"T_128b4_row16_col0\" class=\"data row16 col0\" >alpha_1000_idx_2</td>\n      <td id=\"T_128b4_row16_col1\" class=\"data row16 col1\" >0.665285</td>\n      <td id=\"T_128b4_row16_col2\" class=\"data row16 col2\" >0.837209</td>\n      <td id=\"T_128b4_row16_col3\" class=\"data row16 col3\" >0.893866</td>\n      <td id=\"T_128b4_row16_col4\" class=\"data row16 col4\" >0.787307</td>\n      <td id=\"T_128b4_row16_col5\" class=\"data row16 col5\" >0.834798</td>\n      <td id=\"T_128b4_row16_col6\" class=\"data row16 col6\" >40.881552</td>\n      <td id=\"T_128b4_row16_col7\" class=\"data row16 col7\" >1000</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row17\" class=\"row_heading level0 row17\" >5</th>\n      <td id=\"T_128b4_row17_col0\" class=\"data row17 col0\" >alpha_1000_idx_1</td>\n      <td id=\"T_128b4_row17_col1\" class=\"data row17 col1\" >0.640264</td>\n      <td id=\"T_128b4_row17_col2\" class=\"data row17 col2\" >0.845059</td>\n      <td id=\"T_128b4_row17_col3\" class=\"data row17 col3\" >0.825696</td>\n      <td id=\"T_128b4_row17_col4\" class=\"data row17 col4\" >0.865352</td>\n      <td id=\"T_128b4_row17_col5\" class=\"data row17 col5\" >0.817665</td>\n      <td id=\"T_128b4_row17_col6\" class=\"data row17 col6\" >42.463830</td>\n      <td id=\"T_128b4_row17_col7\" class=\"data row17 col7\" >1000</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row18\" class=\"row_heading level0 row18\" >11</th>\n      <td id=\"T_128b4_row18_col0\" class=\"data row18 col0\" >alpha_inf_idx_3</td>\n      <td id=\"T_128b4_row18_col1\" class=\"data row18 col1\" >0.669800</td>\n      <td id=\"T_128b4_row18_col2\" class=\"data row18 col2\" >0.856054</td>\n      <td id=\"T_128b4_row18_col3\" class=\"data row18 col3\" >0.845318</td>\n      <td id=\"T_128b4_row18_col4\" class=\"data row18 col4\" >0.867067</td>\n      <td id=\"T_128b4_row18_col5\" class=\"data row18 col5\" >0.833641</td>\n      <td id=\"T_128b4_row18_col6\" class=\"data row18 col6\" >42.311102</td>\n      <td id=\"T_128b4_row18_col7\" class=\"data row18 col7\" >inf</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row19\" class=\"row_heading level0 row19\" >17</th>\n      <td id=\"T_128b4_row19_col0\" class=\"data row19 col0\" >alpha_inf_idx_1</td>\n      <td id=\"T_128b4_row19_col1\" class=\"data row19 col1\" >0.624979</td>\n      <td id=\"T_128b4_row19_col2\" class=\"data row19 col2\" >0.841674</td>\n      <td id=\"T_128b4_row19_col3\" class=\"data row19 col3\" >0.806604</td>\n      <td id=\"T_128b4_row19_col4\" class=\"data row19 col4\" >0.879931</td>\n      <td id=\"T_128b4_row19_col5\" class=\"data row19 col5\" >0.807136</td>\n      <td id=\"T_128b4_row19_col6\" class=\"data row19 col6\" >42.125180</td>\n      <td id=\"T_128b4_row19_col7\" class=\"data row19 col7\" >inf</td>\n    </tr>\n    <tr>\n      <th id=\"T_128b4_level0_row20\" class=\"row_heading level0 row20\" >9</th>\n      <td id=\"T_128b4_row20_col0\" class=\"data row20 col0\" >alpha_inf_idx_2</td>\n      <td id=\"T_128b4_row20_col1\" class=\"data row20 col1\" >0.671625</td>\n      <td id=\"T_128b4_row20_col2\" class=\"data row20 col2\" >0.857384</td>\n      <td id=\"T_128b4_row20_col3\" class=\"data row20 col3\" >0.843854</td>\n      <td id=\"T_128b4_row20_col4\" class=\"data row20 col4\" >0.871355</td>\n      <td id=\"T_128b4_row20_col5\" class=\"data row20 col5\" >0.834166</td>\n      <td id=\"T_128b4_row20_col6\" class=\"data row20 col6\" >43.779240</td>\n      <td id=\"T_128b4_row20_col7\" class=\"data row20 col7\" >inf</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}],"execution_count":23}]}