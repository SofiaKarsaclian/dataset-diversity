# Evaluating Dataset Diversity in Media Bias Detection Models

## Description
This repository contains the code, datasets, and supplementary materials for the master thesis, **Evaluating Dataset Diversity in Media Bias Detection Models**. The focus of this research is to investigate how the diversity of datasets can be quantified and its impact on the performance and generalization capabilities of machine learning models, specifically in the task of lexical bias classification.

The thesis explores the role of dataset diversity in training models for detecting bias in media content. It examines how diversity in source and topic coverage affects the model's ability to generalize across different types of content and its downstream performance in bias detection tasks. By assessing how various dimensions of diversity contribute to model fairness, accuracy, and robustness, this work aims to provide insights into how dataset curation practices can improve the reliability and fairness of bias detection systems.

